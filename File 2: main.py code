import cv2
import torch
import numpy as np
from PIL import Image
from diffusers import StableDiffusionXLInstantIDPipeline, ControlNetModel
from insightface.app import FaceAnalysis
import os

# ================= CONFIGURATION =================
# 1. Put your photo filename here
REFERENCE_IMAGE_PATH = "my_selfie.jpg" 

# 2. Describe the image you want to generate
PROMPT = "A realistic photo of a man standing next to Prabhas at a movie set, cinematic lighting, high quality, 8k"
NEGATIVE_PROMPT = "blurry, low quality, distorted face, bad anatomy, cartoon, anime"

# 3. Output filename
OUTPUT_FILENAME = "generated_result.png"
# =================================================

def generate_image():
    # Check if reference image exists
    if not os.path.exists(REFERENCE_IMAGE_PATH):
        print(f"Error: The file '{REFERENCE_IMAGE_PATH}' was not found.")
        print("Please place your selfie in this folder and rename it, or update the config.")
        return

    print("Loading Face Analysis models (InsightFace)...")
    app = FaceAnalysis(name='antelopev2', root='./', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
    app.prepare(ctx_id=0, det_size=(640, 640))

    print("Analyzing reference image...")
    face_image = Image.open(REFERENCE_IMAGE_PATH).convert("RGB")
    face_image_cv = cv2.cvtColor(np.array(face_image), cv2.COLOR_RGB2BGR)
    
    face_info = app.get(face_image_cv)
    
    if len(face_info) == 0:
        print("Error: No face detected in the reference image. Please try a clearer close-up.")
        return
    
    # Sort to find the largest face in the photo (in case there are others in background)
    face_info = sorted(face_info, key=lambda x: (x['bbox'][2] - x['bbox'][0]) * (x['bbox'][3] - x['bbox'][1]))[-1]
    face_emb = face_info['embedding']
    face_kps = Image.fromarray(face_image_cv)

    print("Loading Stable Diffusion + InstantID models...")
    # Load the ControlNet (the "Guider")
    controlnet = ControlNetModel.from_pretrained(
        "InstantX/InstantID", subfolder="ControlNetModel", torch_dtype=torch.float16
    )

    # Load the main pipeline
    pipeline = StableDiffusionXLInstantIDPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0", 
        controlnet=controlnet, 
        torch_dtype=torch.float16
    )
    
    # optimize for GPU
    pipeline.to("cuda")
    pipeline.load_ip_adapter_instantid("InstantX/InstantID")

    print(f"Generating image for prompt: '{PROMPT}'...")
    image = pipeline(
        prompt=PROMPT,
        negative_prompt=NEGATIVE_PROMPT,
        image_embeds=face_emb,
        image=face_kps,
        controlnet_conditioning_scale=0.8, 
        ip_adapter_scale=0.8,
        num_inference_steps=30,
        guidance_scale=5,
    ).images[0]

    image.save(OUTPUT_FILENAME)
    print(f"Success! Image saved as {OUTPUT_FILENAME}")

if _name_ == "_main_":
    generate_image()
